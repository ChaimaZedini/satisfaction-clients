import streamlit as st
import pandas as pd
import numpy as np
import re
import pickle
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

# T√©l√©charger les ressources NLTK (cach√© √† l'utilisateur)
import ssl
try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context

try:
    nltk.data.find('tokenizers/punkt')
except:
    nltk.download('punkt', quiet=True)
try:
    nltk.data.find('corpora/stopwords')
except:
    nltk.download('stopwords', quiet=True)
try:
    nltk.data.find('corpora/wordnet')
except:
    nltk.download('wordnet', quiet=True)

# ============================================
# CONFIGURATION DE L'INTERFACE
# ============================================

st.set_page_config(
    page_title="Analyse de Sentiment Amazon",
    page_icon="üòä",
    layout="centered"
)

# Titre
st.title("üòä Analyse de Satisfaction Client")
st.markdown("---")

# ============================================
# CHARGEMENT DES MOD√àLES
# ============================================

@st.cache_resource
def charger_modeles():
    """Charger les mod√®les Word2Vec et le classifieur"""
    try:
        # Charger Word2Vec
        with open('word2vec_model.pkl', 'rb') as f:
            word2vec_model = pickle.load(f)
        
        # Charger le classifieur
        with open('classifier_model.pkl', 'rb') as f:
            classifier_model = pickle.load(f)
        
        # Charger les statistiques
        with open('model_stats.pkl', 'rb') as f:
            stats = pickle.load(f)
        
        return word2vec_model, classifier_model, stats
    
    except FileNotFoundError:
        st.error("""
        ‚ö†Ô∏è **Mod√®les non trouv√©s !**
        
        Suivez ces √©tapes :
        1. Ex√©cutez d'abord le notebook pour entra√Æner les mod√®les
        2. Assurez-vous que ces fichiers sont pr√©sents :
           - `word2vec_model.pkl`
           - `classifier_model.pkl`
           - `model_stats.pkl`
        """)
        return None, None, None
    
    except Exception as e:
        st.error(f"Erreur de chargement : {e}")
        return None, None, None

# Charger les mod√®les
word2vec_model, classifier_model, stats = charger_modeles()

# ============================================
# FONCTIONS DE TRAITEMENT
# ============================================

# Initialiser les outils NLP
lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words('english'))

def nettoyer_et_tokeniser(texte):
    """Nettoyer et tokeniser un texte"""
    if not texte or pd.isna(texte):
        return []
    
    texte = str(texte).lower()
    
    # Supprimer caract√®res sp√©ciaux
    texte = re.sub(r'[^a-z\s]', ' ', texte)
    
    # Tokenisation simple
    mots = texte.split()
    
    # Supprimer stopwords et mots courts
    mots = [m for m in mots if m not in stop_words and len(m) > 2]
    
    # Lemmatisation
    mots = [lemmatizer.lemmatize(m) for m in mots]
    
    return mots

def creer_vecteur_document(tokens, model):
    """Cr√©er un vecteur document √† partir des tokens"""
    if not tokens:
        return np.zeros(100)  # 100 = dimension Word2Vec
    
    # Filtrer les mots dans le vocabulaire
    mots_valides = [m for m in tokens if m in model.wv]
    
    if not mots_valides:
        return np.zeros(100)
    
    # Moyenne des vecteurs
    return np.mean([model.wv[m] for m in mots_valides], axis=0)

def predire_sentiment(commentaire):
    """Fonction principale de pr√©diction"""
    if word2vec_model is None or classifier_model is None:
        return "Mod√®les non charg√©s", 0.0, []
    
    # 1. Nettoyer le texte
    tokens = nettoyer_et_tokeniser(commentaire)
    
    # 2. V√©rifier si valide
    if len(tokens) == 0:
        return "Texte trop court", 0.0, []
    
    # 3. Cr√©er vecteur document
    vecteur_doc = creer_vecteur_document(tokens, word2vec_model)
    
    # 4. Pr√©diction
    prediction = classifier_model.predict([vecteur_doc])[0]
    proba = classifier_model.predict_proba([vecteur_doc])[0]
    confiance = proba[prediction]
    
    # 5. R√©sultat
    if prediction == 1:
        sentiment = "‚úÖ Client SATISFAIT"
    else:
        sentiment = "‚ùå Client NON SATISFAIT"
    
    return sentiment, confiance, tokens

# ============================================
# INTERFACE UTILISATEUR
# ============================================

# Barre lat√©rale avec informations
st.sidebar.header("üìä Informations du mod√®le")
if stats:
    st.sidebar.metric("Accuracy", f"{stats.get('accuracy', 0):.2%}")
    st.sidebar.metric("Taille du vocabulaire", f"{stats.get('vocab_size', 0):,}")
    if 'class_distribution' in stats:
        dist = stats['class_distribution']
        st.sidebar.write("**R√©partition :**")
        st.sidebar.write(f"- Satisfait : {dist.get(1, 0)}")
        st.sidebar.write(f"- Non satisfait : {dist.get(0, 0)}")

# Section principale
st.subheader("üìù Analysez un commentaire")

# Zone de texte
commentaire = st.text_area(
    "Entrez votre commentaire ci-dessous :",
    height=120,
    placeholder="Exemple : 'This product is excellent! Very good quality and fast delivery.'",
    key="input_text"
)

# Bouton d'analyse
col1, col2 = st.columns([1, 4])
with col1:
    if st.button("üîç Analyser", type="primary", use_container_width=True):
        st.session_state.analyser = True

# Si l'utilisateur clique sur Analyser
if hasattr(st.session_state, 'analyser') and st.session_state.analyser:
    if commentaire.strip():
        with st.spinner("Analyse en cours avec Word2Vec..."):
            # Pr√©diction
            sentiment, confiance, tokens = predire_sentiment(commentaire)
        
        # Affichage des r√©sultats
        st.markdown("---")
        st.subheader("üìä R√©sultat de l'analyse")
        
        # Affichage du sentiment
        if "SATISFAIT" in sentiment:
            st.success(f"## {sentiment}")
            st.balloons()
        else:
            st.error(f"## {sentiment}")
        
        # M√©triques
        col_a, col_b = st.columns(2)
        with col_a:
            st.metric("Confiance", f"{confiance:.1%}")
        with col_b:
            st.metric("Mots analys√©s", len(tokens))
        
        # Barre de progression
        st.progress(float(confiance))
        
        # D√©tails
        with st.expander("üîç Voir les d√©tails d'analyse"):
            st.write("**Texte analys√© :**")
            st.info(f'"{commentaire}"')
            
            st.write("**Mots extraits :**")
            if tokens:
                # Afficher les mots avec des badges color√©s
                html_tokens = ""
                for token in tokens[:30]:  # Limiter √† 30 mots
                    if token in word2vec_model.wv:
                        html_tokens += f'<span style="background:#4CAF50;color:white;padding:3px 8px;margin:2px;border-radius:5px;display:inline-block;">{token}</span> '
                    else:
                        html_tokens += f'<span style="background:#ff9800;color:white;padding:3px 8px;margin:2px;border-radius:5px;display:inline-block;">{token}</span> '
                
                st.markdown(html_tokens, unsafe_allow_html=True)
                
                if len(tokens) > 30:
                    st.write(f"... et {len(tokens) - 30} autres mots")
            else:
                st.write("Aucun mot extrait")
            
            # Information technique
            if word2vec_model:
                st.write(f"**Dimension Word2Vec :** {word2vec_model.vector_size}")
    
    else:
        st.warning("‚ö†Ô∏è Veuillez entrer un commentaire avant d'analyser.")

# Section exemples
st.markdown("---")
st.subheader("üí° Exemples rapides √† tester")

exemples = [
    "This product is amazing! Perfect quality and fast delivery.",
    "Terrible experience. The item broke after 2 days of use.",
    "Good value for money but shipping was a bit slow.",
    "Absolutely love it! Best purchase I've made this year.",
    "Waste of money. Very disappointed with the quality."
]

# Afficher les boutons d'exemples
cols = st.columns(5)
for i, exemple in enumerate(exemples):
    with cols[i]:
        if st.button(f"Ex {i+1}", key=f"btn_{i}"):
            # Mettre √† jour la zone de texte
            st.session_state.input_text = exemple
            # D√©clencher une nouvelle ex√©cution
            st.rerun()

# Instructions d'utilisation
st.markdown("---")
with st.expander("‚ÑπÔ∏è Comment utiliser cette application"):
    st.write("""
    **Instructions :**
    1. √âcrivez un commentaire en anglais dans la zone de texte
    2. Cliquez sur le bouton **"Analyser"**
    3. Consultez le r√©sultat de l'analyse
    
    **Technologie utilis√©e :**
    - **Word2Vec** : Mod√®le d'embedding de mots
    - **R√©gression Logistique** : Classifieur binaire
    
    **Classes de r√©sultat :**
    - ‚úÖ **Client SATISFAIT** : Correspond aux notes 4-5 √©toiles
    - ‚ùå **Client NON SATISFAIT** : Correspond aux notes 1-3 √©toiles
    
    **Note :** Pour de meilleurs r√©sultats, utilisez des commentaires en anglais.
    """)

# Pied de page
st.markdown("---")
st.caption("Projet de Fouille de Donn√©es - Analyse de Sentiment avec Word2Vec")